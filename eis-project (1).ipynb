{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11123808,"sourceType":"datasetVersion","datasetId":6936949}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"rahulhavalad/minor-prjt\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install tensorflow==2.14.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\n# Enable GPU dynamic memory growth (for local environments)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"âœ… GPU memory growth enabled.\")\n    except RuntimeError as e:\n        print(e)\n\n# Constants\nIMG_SIZE = 224\nBATCH_SIZE = 32\nNUM_CLASSES = 16\nEPOCHS = 40  # Allow higher max epochs; EarlyStopping will halt early\n\nTRAIN_DIR = '/kaggle/input/minor-prjt/Cereal_Crop_Disease_Split/Train'\nVALIDATION_DIR = '/kaggle/input/minor-prjt/Cereal_Crop_Disease_Split/Validation'\nTEST_DIR = '/kaggle/input/minor-prjt/Cereal_Crop_Disease_Split/Test'\n\nLABELS = [\n    'Corn_Blight', 'Corn_Common_Rust', 'Corn_Greay_Leaf_Spot', 'Corn_Healthy',\n    'Rice_Bacterial_Blight', 'Rice_Blast', 'Rice_Brown_Spot',\n    'Sorghum_Anthracnose_Red_Rot', 'Sorghum_Cereal_Grain_Molds',\n    'Sorghum_Head_Smut', 'Sorghum_Loose_Smut', 'Sorghum_Rust',\n    'Wheat_Brown_Rust', 'Wheat_Healthy', 'Wheat_Septoria', 'Wheat_Yellow_Rust'\n]\n\n# Preprocessing\ndef preprocess_data(image, label):\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, label\n\ndef load_dataset(directory, shuffle=True):\n    dataset = tf.keras.utils.image_dataset_from_directory(\n        directory,\n        labels='inferred',\n        label_mode='int',\n        class_names=LABELS,\n        image_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        shuffle=shuffle\n    )\n    return dataset.map(preprocess_data).prefetch(tf.data.AUTOTUNE)\n\n# Load datasets\ntrain_dataset = load_dataset(TRAIN_DIR, shuffle=True)\nval_dataset = load_dataset(VALIDATION_DIR, shuffle=False)\ntest_dataset = load_dataset(TEST_DIR, shuffle=False)\n\n# Model architecture\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    include_top=False,\n    weights='imagenet'\n)\nbase_model.trainable = False\n\ninputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = base_model(inputs, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.3)(x)\noutputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\n# Compile\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Early stopping callback\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=2,  # Stop if no improvement in 5 epochs\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Train\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=EPOCHS,\n    callbacks=[early_stop]\n)\n\n# Evaluate\nloss, accuracy = model.evaluate(test_dataset)\nprint(f\"\\nâœ… Test Accuracy: {accuracy:.4f}\")\n\n# Representative dataset for quantization\ndef representative_dataset():\n    for images, _ in train_dataset.take(100):\n        yield [tf.cast(images, tf.float32)]\n\n# Convert to quantized TFLite\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_dataset\nconverter.target_spec.supported_types = [tf.int8]\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\n\ntflite_model = converter.convert()\n\n# Save files\nos.makedirs('/kaggle/working/', exist_ok=True)\n\nwith open('/kaggle/working/cereal_crop_disease_model_quantized.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nwith open('/kaggle/working/labels.txt', 'w') as f:\n    for label in LABELS:\n        f.write(label + '\\n')\n\nprint(\"ðŸš€ Model training completed. Quantized model and labels saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T10:03:39.586621Z","iopub.execute_input":"2025-05-26T10:03:39.586901Z","iopub.status.idle":"2025-05-26T11:44:45.623887Z","shell.execute_reply.started":"2025-05-26T10:03:39.586876Z","shell.execute_reply":"2025-05-26T11:44:45.623132Z"}},"outputs":[{"name":"stderr","text":"2025-05-26 10:03:39.873455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-05-26 10:03:39.873510: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-05-26 10:03:39.873571: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 10844 files belonging to 16 classes.\nFound 1348 files belonging to 16 classes.\nFound 1371 files belonging to 16 classes.\nEpoch 1/40\n339/339 [==============================] - 259s 748ms/step - loss: 1.0753 - accuracy: 0.6585 - val_loss: 0.4797 - val_accuracy: 0.8561\nEpoch 2/40\n339/339 [==============================] - 247s 726ms/step - loss: 0.4627 - accuracy: 0.8525 - val_loss: 0.3316 - val_accuracy: 0.9088\nEpoch 3/40\n339/339 [==============================] - 270s 794ms/step - loss: 0.3307 - accuracy: 0.8941 - val_loss: 0.2802 - val_accuracy: 0.9177\nEpoch 4/40\n339/339 [==============================] - 253s 743ms/step - loss: 0.2725 - accuracy: 0.9138 - val_loss: 0.2368 - val_accuracy: 0.9318\nEpoch 5/40\n339/339 [==============================] - 267s 786ms/step - loss: 0.2295 - accuracy: 0.9319 - val_loss: 0.2223 - val_accuracy: 0.9303\nEpoch 6/40\n339/339 [==============================] - 269s 791ms/step - loss: 0.2027 - accuracy: 0.9396 - val_loss: 0.1964 - val_accuracy: 0.9421\nEpoch 7/40\n339/339 [==============================] - 261s 766ms/step - loss: 0.1798 - accuracy: 0.9449 - val_loss: 0.1841 - val_accuracy: 0.9458\nEpoch 8/40\n339/339 [==============================] - 279s 820ms/step - loss: 0.1648 - accuracy: 0.9517 - val_loss: 0.1756 - val_accuracy: 0.9496\nEpoch 9/40\n339/339 [==============================] - 275s 807ms/step - loss: 0.1485 - accuracy: 0.9554 - val_loss: 0.1687 - val_accuracy: 0.9518\nEpoch 10/40\n339/339 [==============================] - 235s 689ms/step - loss: 0.1381 - accuracy: 0.9587 - val_loss: 0.1638 - val_accuracy: 0.9525\nEpoch 11/40\n339/339 [==============================] - 238s 700ms/step - loss: 0.1287 - accuracy: 0.9615 - val_loss: 0.1614 - val_accuracy: 0.9570\nEpoch 12/40\n339/339 [==============================] - 239s 703ms/step - loss: 0.1182 - accuracy: 0.9670 - val_loss: 0.1620 - val_accuracy: 0.9518\nEpoch 13/40\n339/339 [==============================] - 257s 755ms/step - loss: 0.1118 - accuracy: 0.9673 - val_loss: 0.1522 - val_accuracy: 0.9577\nEpoch 14/40\n339/339 [==============================] - 252s 740ms/step - loss: 0.1114 - accuracy: 0.9666 - val_loss: 0.1490 - val_accuracy: 0.9585\nEpoch 15/40\n339/339 [==============================] - 238s 698ms/step - loss: 0.1050 - accuracy: 0.9696 - val_loss: 0.1519 - val_accuracy: 0.9547\nEpoch 16/40\n339/339 [==============================] - 241s 707ms/step - loss: 0.1005 - accuracy: 0.9702 - val_loss: 0.1468 - val_accuracy: 0.9533\nEpoch 17/40\n339/339 [==============================] - 236s 694ms/step - loss: 0.0944 - accuracy: 0.9721 - val_loss: 0.1405 - val_accuracy: 0.9585\nEpoch 18/40\n339/339 [==============================] - 256s 752ms/step - loss: 0.0926 - accuracy: 0.9713 - val_loss: 0.1463 - val_accuracy: 0.9592\nEpoch 19/40\n339/339 [==============================] - 231s 679ms/step - loss: 0.0898 - accuracy: 0.9746 - val_loss: 0.1532 - val_accuracy: 0.9555\nEpoch 20/40\n339/339 [==============================] - 234s 687ms/step - loss: 0.0848 - accuracy: 0.9734 - val_loss: 0.1477 - val_accuracy: 0.9592\nEpoch 21/40\n339/339 [==============================] - 233s 685ms/step - loss: 0.0804 - accuracy: 0.9766 - val_loss: 0.1485 - val_accuracy: 0.9577\nEpoch 22/40\n339/339 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 17.\n339/339 [==============================] - 229s 672ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.1498 - val_accuracy: 0.9547\nEpoch 22: early stopping\n43/43 [==============================] - 27s 624ms/step - loss: 0.1393 - accuracy: 0.9555\n\nâœ… Test Accuracy: 0.9555\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"ðŸš€ Model training completed. Quantized model and labels saved.\n","output_type":"stream"},{"name":"stderr","text":"fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T10:03:24.551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}